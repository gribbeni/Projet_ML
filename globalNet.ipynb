{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from functools import reduce\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from torch.autograd import Variable\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import loaders as l\n",
    "import models as m\n",
    "import train_eval as te\n",
    "\n",
    "import cv2\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import pprint\n",
    "\n",
    "from ImageClassification import helpers as h\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path='C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/test_v2'\n",
    "net = m.BaseNet_v2()\n",
    "net.load_state_dict(torch.load(saved_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters \n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "image = cv2.imread(\"C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/test11.jpg\")\n",
    "winSize=(winW, winH) = (36, 36)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(), \n",
    "     transforms.ToTensor(), \n",
    "     transforms.Normalize(mean=(0,),std=(1,))])\n",
    "#face_detected=0\n",
    "#layer=0\n",
    "color_noFace=(255,0,0)\n",
    "color_face=(0, 255, 0)\n",
    "sleep=0.0015\n",
    "sc=1.2\n",
    "face_detected=0\n",
    "layer=0\n",
    "centers=[]\n",
    "top_left=[]\n",
    "all_layers=[]\n",
    "all_prob=[]\n",
    "all_x=[]\n",
    "all_y=[]\n",
    "nb_layers=0\n",
    "sliding_step=10\n",
    "toPrint=False#True if you want to see animations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "#global_pyramid(image,scale,stepSize,windowSize,toPrint):\n",
    "    \n",
    "    \n",
    "# loop over the image pyramid\n",
    "for resized in h.pyramid(image, scale=sc):\n",
    "\n",
    "    # loop over the sliding window for each layer of the pyramid\n",
    "\n",
    "    for (x, y, window) in h.sliding_window(resized, stepSize=sliding_step, windowSize=(winW, winH)):\n",
    "        # if the window does not meet our desired window size, ignore it\n",
    "        if window.shape[0] != winH or window.shape[1] != winW:\n",
    "            continue\n",
    "\n",
    "        # window processing\n",
    "\n",
    "        color=color_noFace\n",
    "        sleep=0.005\n",
    "\n",
    "        im = Image.fromarray(window.astype('uint8'), 'RGB')\n",
    "        im=transform(im)\n",
    "        im = im.unsqueeze(0)\n",
    "\n",
    "        outputs=net(im)\n",
    "\n",
    "        prob=torch.nn.functional.softmax(outputs, dim=1).detach()[0][1].numpy()\n",
    "\n",
    "        y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "\n",
    "        prediction=np.array(y_pred_tags)\n",
    "\n",
    "        if prediction==1 and prob>0.9:\n",
    "\n",
    "            face_detected+=1\n",
    "            #top left corner of the window\n",
    "            x1=int(x*pow(sc,layer))\n",
    "            y1=int(y*pow(sc,layer))\n",
    "            top_left.append((x1,y1))\n",
    "\n",
    "            #middle of the window\n",
    "            x2=int(x1+(winW*pow(sc,layer)/2))\n",
    "            y2=int(y1+(winH*pow(sc,layer)/2))\n",
    "            centers.append((x2,y2))\n",
    "\n",
    "            all_layers.append(layer)\n",
    "            all_prob.append(prob)\n",
    "\n",
    "            #print(new_face)\n",
    "            color=color_face\n",
    "            sleep=0.5\n",
    "\n",
    "\n",
    "        #draw the window\n",
    "        if toPrint : \n",
    "            clone = resized.copy()\n",
    "            cv2.rectangle(clone, (x, y), (x + winW, y + winH), color, 2)\n",
    "            cv2.imshow(\"Window\", clone)\n",
    "            cv2.waitKey(1)\n",
    "            time.sleep(sleep)\n",
    "\n",
    "    layer+=1\n",
    "if toPrint :        \n",
    "    print(face_detected)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows() \n",
    "\n",
    "nb_layers=layer\n",
    "#print(nb_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows a point for every sliding window classed as Face\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "img_clone= image.copy()\n",
    "\n",
    "for center in centers : \n",
    "\n",
    "    cv2.circle(img_clone, (int(center[0]), int(center[1])),2,color_face, 2)\n",
    "\n",
    "cv2.imshow(\"Detected faces at step 1\", img_clone)\n",
    "\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Better analyze the zones previously detected by building a mini-pyramid around them\n",
    "#It allows to get more points to analyze in the next cell and to remove some false positifs of the cell above\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "sliding_little_step = 2\n",
    "top_left_precise = []\n",
    "centers_precise = []\n",
    "all_layers_precise = []\n",
    "all_prob_precise = []\n",
    "\n",
    "for i in range(len(centers)):\n",
    "    \n",
    "    p=top_left[i]\n",
    "    l=all_layers[i]\n",
    "\n",
    "    layer=0\n",
    "\n",
    "    y_min=p[1]\n",
    "    y_max=p[1]+int(winH*pow(sc,l))\n",
    "    x_min=p[0]\n",
    "    x_max=p[0]+int(winW*pow(sc,l))\n",
    "    \n",
    "    #mini pyramid centered around a possible face\n",
    "    for (resized,x_crop,y_crop) in h.pyramid_v2(image[y_min:y_max,x_min:x_max], crop=5,layer=l,scale=sc):\n",
    "    # loop over the sliding window for each layer of the pyramid\n",
    "        for (x, y, window) in h.sliding_window(resized, stepSize=sliding_little_step, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            color=color_noFace\n",
    "            sleep=0.005\n",
    "\n",
    "            im = Image.fromarray(window.astype('uint8'), 'RGB')\n",
    "            im=transform(im)\n",
    "            im = im.unsqueeze(0)\n",
    "            outputs=net(im)\n",
    "            prob=torch.nn.functional.softmax(outputs, dim=1).detach()[0][1].numpy()\n",
    "            #print(prob)\n",
    "            y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "            _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "            prediction=np.array(y_pred_tags)\n",
    "            new_face=[]\n",
    "\n",
    "            if prediction==1 and prob>0.9:\n",
    "                face_detected+=1\n",
    "                #top left corner of the window\n",
    "                x1 = int(x_min + x*pow(sc,layer)+x_crop)\n",
    "                y1 = int(y_min + y*pow(sc,layer)+y_crop)\n",
    "                top_left_precise.append((x1,y1))\n",
    "                #middle of the window\n",
    "                x2 = int(x1+(winW*pow(sc,layer)/2))\n",
    "                y2 = int(y1+(winH*pow(sc,layer)/2))\n",
    "                centers_precise.append((x2,y2))\n",
    "                all_layers_precise.append(layer)\n",
    "                all_prob_precise.append(prob)\n",
    "                \n",
    "                #print(new_face)\n",
    "                color=color_face\n",
    "                sleep=0.025\n",
    "                \n",
    "            #draw the window\n",
    "            if toPrint :\n",
    "                clone = resized.copy()\n",
    "                cv2.rectangle(clone, (x, y), (x + winW, y + winH), color, 2)\n",
    "                cv2.imshow(\"Window\", clone)\n",
    "                cv2.waitKey(1)\n",
    "                time.sleep(sleep)\n",
    "            \n",
    "        layer+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of estimated clusters : 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clustering with MeanShift :it finds the number and position of of clusters and remove unclasteed points\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "img_clone= image.copy()\n",
    "data=centers_precise\n",
    "   \n",
    "bandwidth = estimate_bandwidth(data, quantile=0.2)\n",
    "\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True,cluster_all=False)\n",
    "ms.fit(data)\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "#print(cluster_centers)\n",
    "\n",
    "colors=[(255,0,0),(0,255,0),(0,0,255),(55,100,50),(25,130,50)]\n",
    "i=0\n",
    "for center in cluster_centers:\n",
    "    \n",
    "    cv2.circle(img_clone, (int(center[0]), int(center[1])),3,colors[i], 3)\n",
    "    cv2.rectangle(img_clone, ( int(center[0])-36*int(nb_layers/10), int(center[1])-36*int(nb_layers/10) ) , (int(center[0])+36*int(nb_layers/10), int(center[1])+36*int(nb_layers/10) ), colors[i], 2)\n",
    "    i+=1\n",
    "    i%=len(colors)\n",
    "    \n",
    "for j in range(len(data)) : \n",
    "    cv2.circle(img_clone,data[j],1,(0,0,0), 1)\n",
    "    \n",
    "plt.show()\n",
    "cv2.imshow(\"Layer\", img_clone)\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    880\n",
      "-1    731\n",
      " 1    317\n",
      " 2    253\n",
      " 3     14\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cluster filtering : we only show the cluster(s) with the biggest number(s) of elements\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "img_clone= image.copy()\n",
    "\n",
    "\n",
    "label_distribution=pd.Series(labels).value_counts()\n",
    "print(label_distribution)\n",
    "treshold=0.8*label_distribution.max()\n",
    "faces_clusters=label_distribution[label_distribution>treshold].index.to_list()\n",
    "face_centers=[cluster_centers[i] for i in faces_clusters]\n",
    "\n",
    "for center in face_centers:\n",
    "    \n",
    "    #cv2.circle(img_clone, (int(center[0]), int(center[1])),2,color_face, 2)\n",
    "    if nb_layers<8 : \n",
    "        nb_layers=8\n",
    "    cv2.rectangle(img_clone, ( int(center[0])-36*int(nb_layers/10), int(center[1])-36*int(nb_layers/10) ) , (int(center[0])+36*int(nb_layers/10), int(center[1])+36*int(nb_layers/10) ),color_face, 2)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "cv2.imshow(\"Faces\", img_clone)\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
