{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from functools import reduce\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loaders as l\n",
    "import models as m\n",
    "import train_eval as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/train_images\"\n",
    "test_dir = \"C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/test_images\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(), \n",
    "     transforms.ToTensor(), \n",
    "     transforms.Normalize(mean=(0,),std=(1,))])\n",
    "\n",
    "valid_size = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "train_loader,valid_loader,test_loader=l.make_all_loaders(train_dir,test_dir,transform,valid_size,batch_size)\n",
    "classes = ('noface','face')\n",
    "\n",
    "print(train_loader.dataset.targets.count(0))\n",
    "print(train_loader.dataset.targets.count(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = m.BaseNet_v3()\n",
    "print(net)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optim.Adam(net.parameters(), lr=0.001)\n",
    "#optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs=30\n",
    "\n",
    "#Training\n",
    "print(\"Started Training\")\n",
    "all_losses,all_accuracies,all_f1scores,all_roc_aucc,best_params= te.train_v1(net,criterion,optimizer,epochs,train_loader,valid_loader,device)\n",
    "            \n",
    "#plt.plot(all_losses, color='blue')\n",
    "#plt.plot(all_f1scores, color='red')\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(all_f1scores, color='red')\n",
    "plt.title('Evolution of f1 score during epochs')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(all_losses, color='blue')\n",
    "plt.title('Evolution of losses during epochs')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarder celui avec les meilleures metrics et pas le dernier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path='C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/firstModel2'\n",
    "torch.save(best_params, saved_model_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = m.BaseNet_v3()\n",
    "net.load_state_dict(torch.load(saved_model_path))\n",
    "net.to(device)\n",
    "print(net)\n",
    "#saved_model_path='C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/BaseNet_v2_lo0001_30ep'\n",
    "#torch.save(net.state_dict(), saved_model_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(all_roc_aucc, color='blue')\n",
    "plt.title('ROC curve during epochs')\n",
    "#f1,_,_,_,roc = te.calc_metrics_v1(net,test_loader,False)\n",
    "#print(f1)\n",
    "#print(roc)\n",
    "#s=roc_auc_score(all_labels, all_predicted)\n",
    "#print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "_,_,_,cm,_=te.calc_metrics_v1(net,test_loader,True,device) \n",
    "sns.heatmap(cm, annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
