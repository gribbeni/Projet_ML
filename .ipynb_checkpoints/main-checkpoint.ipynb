{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from functools import reduce\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loaders as l\n",
    "import models as m\n",
    "import train_eval as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/train_images\"\n",
    "test_dir = \"C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/test_images\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(), \n",
    "     transforms.ToTensor(), \n",
    "     transforms.Normalize(mean=(0,),std=(1,))])\n",
    "\n",
    "valid_size = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "train_loader,valid_loader,test_loader=l.make_all_loaders(train_dir,test_dir,transform,valid_size,batch_size)\n",
    "classes = ('noface','face')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33783\\anaconda3\\envs\\insa-cap\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1, 2000] loss: 0.155 f1_score on validation set : 0.947\n",
      "[ 2, 2000] loss: 0.038 f1_score on validation set : 0.968\n",
      "[ 3, 2000] loss: 0.028 f1_score on validation set : 0.976\n",
      "[ 4, 2000] loss: 0.018 f1_score on validation set : 0.980\n",
      "[ 5, 2000] loss: 0.013 f1_score on validation set : 0.983\n",
      "[ 6, 2000] loss: 0.010 f1_score on validation set : 0.986\n",
      "[ 7, 2000] loss: 0.009 f1_score on validation set : 0.987\n",
      "[ 8, 2000] loss: 0.007 f1_score on validation set : 0.988\n",
      "[ 9, 2000] loss: 0.006 f1_score on validation set : 0.989\n",
      "[10, 2000] loss: 0.005 f1_score on validation set : 0.990\n",
      "[11, 2000] loss: 0.005 f1_score on validation set : 0.991\n",
      "[12, 2000] loss: 0.004 f1_score on validation set : 0.992\n",
      "[13, 2000] loss: 0.004 f1_score on validation set : 0.992\n",
      "[14, 2000] loss: 0.002 f1_score on validation set : 0.993\n",
      "[15, 2000] loss: 0.003 f1_score on validation set : 0.993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20a8ecb6040>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = m.BaseNet()\n",
    "print(net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#l'original mais moins bonne #optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs=15\n",
    "\n",
    "#Training\n",
    "\n",
    "all_labels,all_predicted,all_losses,all_accuracies,all_f1scores= te.train_v1(net,criterion,optimizer,epochs,train_loader,valid_loader)\n",
    "            \n",
    "plt.plot(all_losses, color='blue')\n",
    "plt.plot(all_f1scores, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path='C:/Users/33783/Desktop/start_deep/start_deep/Projet_ML/firstModel'\n",
    "torch.save(net.state_dict(), saved_model_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = m.BaseNet()\n",
    "net.load_state_dict(torch.load(saved_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set\n",
      "f1_score 0.9926067614848503\n",
      "precision 0.9926553533424576\n",
      "recall 0.9925590634279485\n",
      "confusion matrix\n",
      " [[9.93244061e-01 6.64358027e-03 8.35489280e-05 2.88099752e-05]\n",
      " [8.05108354e-03 9.91869117e-01 6.09380985e-05 1.88617924e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9926067614848503,\n",
       " 0.9926553533424576,\n",
       " 0.9925590634279485,\n",
       " array([[9.93244061e-01, 6.64358027e-03, 8.35489280e-05, 2.88099752e-05],\n",
       "        [8.05108354e-03, 9.91869117e-01, 6.09380985e-05, 1.88617924e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.calc_metrics_v1(net,test_loader,all_labels,all_predicted,show=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  6818   13\n",
      "1   526  271\n"
     ]
    }
   ],
   "source": [
    "#print(all_labels)\n",
    "#print()\n",
    "#print()\n",
    "#print('---------------------------------------------------------------')\n",
    "#print(all_predicted)\n",
    "#te.calc_metrics_v1(net,test_loader,all_labels,all_predicted,show=True) \n",
    "#import pandas as pd\n",
    "#import sklearn \n",
    "\n",
    "all_predicted=[]\n",
    "all_labels=[]\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "            _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "            all_predicted.extend(np.array(y_pred_tags))\n",
    "            all_labels.extend(np.array(labels))\n",
    "\n",
    "print(pd.DataFrame(sklearn.metrics.confusion_matrix(all_labels, all_predicted)))#, columns=classes, index=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_loader.dataset.targets)\n",
    "#print(pd.DataFrame(sklearn.metrics.confusion_matrix(bow_y_test, bow_y_pred), columns=CLASS_NAMES, index=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 92 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of noface : 99 %\n",
      "Accuracy of  face : 36 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
