{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load data\n",
    "train_dir = 'C:/Users/33783/Desktop/start_deep/start_deep/'\n",
    "test_dir = 'C:/Users/33783/Desktop/start_deep/start_deep/'\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(), \n",
    "     transforms.ToTensor(), \n",
    "     transforms.Normalize(mean=(0,),std=(1,))])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "valid_size = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices_train = list(range(num_train))\n",
    "np.random.shuffle(indices_train)\n",
    "split_tv = int(np.floor(valid_size * num_train))\n",
    "train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_new_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=1)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "classes = ('noface','face')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor batch in dataiter : \\n    images, labels = batch #dataiter.next()\\n\\n    # show images\\n    imshow(torchvision.utils.make_grid(images))\\n    #print(' '.join('%5s' % classes[labels[j]] for j in range(len(images))))\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Show train data : shows a grid for each batch\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "\n",
    "#dataiter = iter(train_loader) #list of 5 batches\n",
    "'''\n",
    "for batch in dataiter : \n",
    "    images, labels = batch #dataiter.next()\n",
    "\n",
    "    # show images\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    #print(' '.join('%5s' % classes[labels[j]] for j in range(len(images))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN du prof\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6* 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_debug(self, x):\n",
    "        \n",
    "        # Max pooling over a (2, 2) window\n",
    "        print(\"input\")\n",
    "        print(x.shape)\n",
    "        print(\"conv1\")\n",
    "        x=self.conv1(x)\n",
    "        print(x.shape)\n",
    "        print(\"relu\")\n",
    "        x=F.relu(x)\n",
    "        print(x.shape)\n",
    "        print(\"maxpool2d\")\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        print(x.shape)\n",
    "        \n",
    "        # Max pooling over a (2, 2) window\n",
    "        print(\"input\")\n",
    "        print(x.shape)\n",
    "        print(\"conv2\")\n",
    "        x=self.conv2(x)\n",
    "        print(x.shape)\n",
    "        print(\"relu\")\n",
    "        x=F.relu(x)\n",
    "        print(x.shape)\n",
    "        print(\"maxpool2d\")\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        print(x.shape)\n",
    "        \n",
    "        print(\"view\")\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        print(x.shape)\n",
    "        \n",
    "        print(\"fc1\")\n",
    "        x=self.fc1(x)\n",
    "        print(x.shape)\n",
    "        print(\"relu\")\n",
    "        x = F.relu(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        print(\"fc2\")\n",
    "        x=self.fc2(x)\n",
    "        print(x.shape)\n",
    "        print(\"relu\")\n",
    "        x = F.relu(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        print(\"fc3\")\n",
    "        x = self.fc3(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        #print(num_features)\n",
    "        return num_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "[1,   500] loss: 0.110\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Training\")\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "         # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "            (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'C:/Users/33783/Desktop/start_deep/start_deep/Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
